package go_as

import (
	"context"
	"encoding/json"
	"fmt"
	"log/slog"
	"regexp"
	"strings"
	"time"

	mcpcore "github.com/mark3labs/mcp-go/mcp"
)

// Agent struct represents a new kind of agent that is decoupled from the LLM during task execution.
type Agent struct {
	llmClient      *LLMClient
	mcpClients     map[string]*MCPClient
	logger         *slog.Logger
	history        []Message    // Full conversation history for the LLM
	availableTools []Tool       // Tools fetched from MCPs
	synthesizer    *Synthesizer // Add synthesizer to agent struct for reuse

	// New fields for multi-step orchestration
	currentPlan    []string // Stores the high-level plan generated by the Orchestrator persona
	currentStepIdx int      // Tracks which step of the plan Nexus is currently on
	originalQuery  string   // Store the initial user query for consistent context
}

// NewAgent creates a new instance of the Agent.
func NewAgent(llmClient *LLMClient, mcpClients map[string]*MCPClient, logger *slog.Logger, availableTools []Tool) *Agent {
	return &Agent{
		llmClient:      llmClient,
		mcpClients:     mcpClients,
		logger:         logger,
		history:        []Message{},
		availableTools: availableTools,
		synthesizer:    NewSynthesizer(), // Initialize the synthesizer here
		currentPlan:    nil,
		currentStepIdx: 0,
		originalQuery:  "",
	}
}

// Execute is responsible for executing the agent's tasks.
func (a *Agent) Execute(ctx context.Context, query string) (string, error) {
	a.originalQuery = query
	// Initialize history with only the original user query.
	// The system prompt for planning will be added dynamically per retry.
	a.history = []Message{{Role: "user", Content: query}}

	// Declare variables outside the loop to ensure they are in scope for Phase 2
	var llmResponse *ChatCompletionResponse
	var message Message // Will hold llmResponse.Choices[0].Message
	var firstToolCall *ToolCall
	var planFound bool        // To track if a parsable plan was successfully obtained
	var lastLLMContent string // Store content of the last LLM response for error reporting

	// --- Phase 1: Orchestrator (Planning) ---
	const maxPlanningRetries = 3 // Define how many times to retry planning
	for retryCount := 0; retryCount < maxPlanningRetries; retryCount++ {
		a.logger.Info("Agent: Entering Orchestrator (Planning) phase.", "retry", retryCount)

		// Construct messages for this specific LLM call for planning.
		// It should always be [system_prompt, user_query] to avoid "two assistant messages" issue on retries.
		// The full 'a.history' is only built up *after* a successful planning phase.
		planningMessages := []Message{
			{Role: "system", Content: getOrchestratorSystemPrompt(a.availableTools)}, // Use the new, concise tool formatting
			{Role: "user", Content: a.originalQuery},                                 // Use the original query directly for planning
		}

		// Log the full planning messages being sent to the LLM for debugging
		planningMessagesJSON, _ := json.MarshalIndent(planningMessages, "", "  ")
		a.logger.Info("Agent: Sending planning messages to LLM.", "messages", string(planningMessagesJSON), "retry", retryCount)

		var currentLLMResponse *ChatCompletionResponse // Use a temporary var for this iteration's response
		currentLLMResponse, err := a.llmClient.CallChatCompletion(ctx, planningMessages, a.availableTools)
		if err != nil {
			a.logger.Error("Orchestrator planning LLM call failed.", "error", err, "retry", retryCount)
			if retryCount == maxPlanningRetries-1 {
				return "", fmt.Errorf("orchestrator planning failed after %d retries: %w", maxPlanningRetries, err)
			}
			time.Sleep(1 * time.Second) // Small delay before retrying
			continue                    // Retry
		}

		// Assign to the outer-scoped llmResponse and message
		llmResponse = currentLLMResponse
		message = llmResponse.Choices[0].Message
		lastLLMContent = message.Content // Store content for potential error reporting

		// --- Robust Parsing Logic ---
		// 1. Extract Plan
		planContent, foundPlan := extractContentBetweenTags(message.Content, "<plan>", "</plan>")
		if !foundPlan {
			a.logger.Error("Agent: Orchestrator did not provide a parsable plan (missing <plan> tags).", "llm_response_content", message.Content, "retry", retryCount)
			if retryCount == maxPlanningRetries-1 {
				return "", fmt.Errorf("orchestrator did not provide a parsable plan after %d retries. Last LLM content: '%s'", maxPlanningRetries, lastLLMContent)
			}
			time.Sleep(1 * time.Second) // Small delay before retrying
			continue                    // Retry
		}

		// 2. Extract Tool Calls JSON from the *entire* message content
		toolCallsJSONStr, foundToolCalls := extractToolCallsJSON(message.Content)

		// If plan is found, then populate a.history with the successful planning interaction.
		// This ensures a.history is correct for the Nexus execution phase.
		// We add the system prompt and the *successful* assistant message from the planning phase.
		a.history = append([]Message{{Role: "system", Content: getOrchestratorSystemPrompt(a.availableTools)}}, a.history...) // Add system prompt
		a.history = append(a.history, message)                                                                                // Add the successful assistant message to history

		a.currentPlan = parseNumberedList(planContent)
		a.logger.Info("Agent: Generated plan.", "plan", strings.Join(a.currentPlan, "; "))
		planFound = true // Mark that a plan was successfully obtained

		if foundToolCalls {
			var parsedToolCalls []ToolCall
			if err := json.Unmarshal([]byte(toolCallsJSONStr), &parsedToolCalls); err != nil {
				a.logger.Error("Agent: Failed to unmarshal tool calls JSON.", "error", err, "json_string", toolCallsJSONStr, "retry", retryCount)
				if retryCount == maxPlanningRetries-1 {
					return "", fmt.Errorf("failed to unmarshal tool calls JSON after %d retries: %w", maxPlanningRetries, err)
				}
				time.Sleep(1 * time.Second) // Small delay before retrying
				continue                    // Retry
			}
			if len(parsedToolCalls) > 0 {
				firstToolCall = &parsedToolCalls[0]
				a.logger.Info("Agent: First action is a tool call.", "tool", firstToolCall.Function.Name)
			}
		} else {
			a.logger.Info("Agent: No tool calls JSON found in Orchestrator response. Assuming direct answer or no immediate action.")
			// If no tool calls found, it means the LLM should have provided a direct answer.
			// We'll rely on the Nexus phase to handle the final answer or further steps.
		}

		break // Plan successfully generated and tool call (if any) identified, exit retry loop
	}

	// If after all retries, no plan was found, return an error
	if !planFound {
		return "", fmt.Errorf("failed to obtain a parsable plan from Orchestrator after multiple retries. Last LLM content: '%s'", lastLLMContent)
	}

	// --- Phase 2: Nexus (Execution Loop) ---
	a.logger.Info("Agent: Entering Nexus (Execution) phase.")
	for {
		// If the LLM provided a final answer and no more tools, we're done.
		// This check needs to be against the 'message' variable which holds the *latest* LLM response.
		if message.Content != "" && (message.ToolCalls == nil || len(message.ToolCalls) == 0) {
			a.logger.Info("Agent: Nexus provided final answer.")
			// Optionally, use the Reconnector here for a consistent final summary
			reconnector := NewReconnector(a.llmClient)
			finalSummary, reconErr := reconnector.Reconnect(ctx, a.history)
			if reconErr != nil {
				a.logger.Error("Agent: Failed to reconnect final summary.", "error", reconErr)
				return message.Content, fmt.Errorf("failed to get final summary, returning raw LLM content: %w", reconErr)
			}
			return finalSummary, nil
		}

		// Execute the tool call if one was recommended (either from planning or previous Nexus step)
		if firstToolCall != nil { // Handle the tool call potentially generated during planning phase
			a.logger.Info("Agent: Executing first planned tool call.", "tool", firstToolCall.Function.Name, "arguments", firstToolCall.Function.Arguments)
			toolResult, execErr := a.executeToolCall(ctx, firstToolCall)
			if execErr != nil {
				toolResultMsg := Message{Role: "tool", Content: fmt.Sprintf("Tool execution failed: %v", execErr)}
				a.logger.Error("Agent: Tool execution failed.", "tool", firstToolCall.Function.Name, "error", execErr)
				a.history = append(a.history, toolResultMsg)
			} else {
				synthesizedResult, err := a.synthesizer.Synthesize(toolResult) // Use the agent's synthesizer
				if err != nil {
					return "", fmt.Errorf("failed to synthesize tool result: %w", err)
				}
				toolResultMsg := Message{Role: "tool", Content: synthesizedResult}
				a.history = append(a.history, toolResultMsg)
				a.logger.Info("Agent: Tool execution successful.", "tool", firstToolCall.Function.Name, "result", synthesizedResult)
			}
			firstToolCall = nil // Clear after first execution to move to Nexus-driven calls
			a.currentStepIdx++  // Increment step after execution
		} else {
			// Get the next action from Nexus based on the plan and history
			a.logger.Info("Agent: Requesting next action from Nexus.", "current_step_idx", a.currentStepIdx, "plan_length", len(a.currentPlan))

			// For Nexus execution, always append the system prompt to the *current* history
			nexusMessages := append([]Message{{Role: "system", Content: getNexusSystemPrompt(a.originalQuery, a.currentPlan, a.currentStepIdx, a.availableTools)}}, a.history...)
			currentLLMResponse, err := a.llmClient.CallChatCompletion(ctx, nexusMessages, a.availableTools) // Use temp var
			if err != nil {
				return "", fmt.Errorf("nexus execution failed: %w", err)
			}

			// Assign to the outer-scoped message
			llmResponse = currentLLMResponse
			message = llmResponse.Choices[0].Message
			a.history = append(a.history, message) // Add Nexus's response to history

			if message.ToolCalls != nil && len(message.ToolCalls) > 0 {
				// Nexus recommended a tool, execute it
				a.logger.Info("Agent: Nexus recommended tool.", "tool", message.ToolCalls[0].Function.Name, "arguments", message.ToolCalls[0].Function.Arguments)
				toolResult, execErr := a.executeToolCall(ctx, &message.ToolCalls[0])
				if execErr != nil {
					toolResultMsg := Message{Role: "tool", Content: fmt.Sprintf("Tool execution failed: %v", execErr)}
					a.logger.Error("Agent: Tool execution failed.", "tool", message.ToolCalls[0].Function.Name, "error", execErr)
					a.history = append(a.history, toolResultMsg)
				} else {
					synthesizedResult, err := a.synthesizer.Synthesize(toolResult) // Use the agent's synthesizer
					if err != nil {
						return "", fmt.Errorf("failed to synthesize tool result: %w", err)
					}
					toolResultMsg := Message{Role: "tool", Content: synthesizedResult}
					a.history = append(a.history, toolResultMsg)
					a.logger.Info("Agent: Tool execution successful.", "tool", message.ToolCalls[0].Function.Name, "result", synthesizedResult)
				}
				a.currentStepIdx++ // Increment step after successful execution
			} else {
				// Nexus did not recommend a tool. It might be done or stuck.
				if llmResponse.Choices[0].FinishReason == "stop" && message.Content != "" {
					a.logger.Info("Agent: Nexus indicated task completion with a final answer.")
					// Optionally, use the Reconnector here for a consistent final summary
											reconnector := NewReconnector(a.llmClient)
						finalSummary, reconErr := reconnector.Reconnect(ctx, a.history)
						if reconErr != nil {
							a.logger.Error("Agent: Failed to reconnect final summary.", "error", reconErr)
							return message.Content, fmt.Errorf("failed to get final summary, returning raw LLM content: %w", reconErr)
						}
						return finalSummary, nil
				} else {
					// This indicates Nexus might be stuck or unable to proceed.
					a.logger.Warn("Agent: Nexus did not recommend a tool and did not provide a final answer. Potentially stuck.", "llm_response_content", message.Content, "finish_reason", llmResponse.Choices[0].FinishReason)
					return "", fmt.Errorf("nexus agent unable to complete task: %s", message.Content) // Or a more specific error
				}
			}
		}
	}
}

// executeToolCall is responsible for executing a tool call.
func (a *Agent) executeToolCall(ctx context.Context, toolCall *ToolCall) (*mcpcore.CallToolResult, error) {
	a.logger.Info("Executing tool call", "tool_name", toolCall.Function.Name, "arguments", toolCall.Function.Arguments)

	parts := strings.SplitN(toolCall.Function.Name, ".", 2)
	if len(parts) != 2 {
		return nil, fmt.Errorf("invalid tool name format from LLM: %s", toolCall.Function.Name)
	}
	agentAlias := parts[0]
	toolName := parts[1]

	client, ok := a.mcpClients[agentAlias]
	if !ok {
		return nil, fmt.Errorf("agent %s not connected", agentAlias)
	}

	var toolArgs map[string]interface{}
	if err := json.Unmarshal([]byte(toolCall.Function.Arguments), &toolArgs); err != nil {
		return nil, fmt.Errorf("failed to unmarshal tool arguments: %w", err)
	}

	ctx, cancel := context.WithTimeout(ctx, 30*time.Second) // Longer timeout for tool execution
	defer cancel()

	result, err := client.CallTool(ctx, toolName, toolArgs)
	if err != nil {
		return nil, fmt.Errorf("tool execution failed: %w", err)
	}

	if result.IsError {
		// Attempt to provide a more structured error message if the content is text.
		if len(result.Content) > 0 {
			if textContent, ok := result.Content[0].(mcpcore.TextContent); ok {
				return nil, fmt.Errorf("tool call failed with error: %s", textContent.Text)
			}
		}
		return nil, fmt.Errorf("tool call failed with unspecified error")
	}

	return result, nil
}

// getOrchestratorSystemPrompt now uses the more concise formatToolsForOrchestrator
func getOrchestratorSystemPrompt(tools []Tool) string {
	formattedTools := formatToolsForOrchestrator(tools) // Use the new, concise formatter

	// Use raw string literal for cleaner prompt formatting
	return fmt.Sprintf(`You are the 'Nexus Orchestrator'. Your sole purpose is to plan complex tasks and recommend the first action.

**User Request:**
[This will be automatically appended by the LLM client]

**IMPORTANT:**
- If the user's request is a simple greeting (e.g., "hello", "hi") or can be answered directly from your general knowledge without needing any tools, provide your final answer immediately. In this case, output <plan>1. Provide a direct answer.</plan> followed by {"tool_calls": []} and your direct answer.
- Otherwise, proceed with planning and tool recommendation.

**YOUR THOUGHT PROCESS (Think step-by-step before responding):**
1.  **Understand the User's Intent:** Carefully analyze the user's request.
2.  **Consult Available Tools:** Review the 'Available Tools (Concise Summary)' to see if any tools are relevant to the user's request.
3.  **Formulate a Plan:**
    * If a direct answer is sufficient (e.g., greetings, simple facts), create a plan with "1. Provide a direct answer."
    * If tools are needed, break down the request into a numbered list of logical steps. For each step, identify the specific tool (from 'Available Tools') that will be used. Describe any data flow between steps.
4.  **Determine First Action:** Decide if the first step of the plan requires a tool call.
5.  **Construct Output:** Generate the plan within <plan> and </plan> tags. Immediately after the </plan> tag, output the JSON for the first tool call (or {"tool_calls": []} if no tool is needed).

**Your Task:**
You MUST provide your response in the following strict format:
<plan>
Your numbered step-by-step plan here.
</plan>
{"tool_calls": [{"id": "call_abc", "type": "function", "function": {"name": "tool.name", "arguments": "{\"param\":\"value\"}"}}]} OR {"tool_calls": []} followed by your direct answer if no tools are needed.

**Available Tools (Concise Summary):**
%s

Example Output (for a tool-requiring task):
<plan>
1. Search for current weather in London using 'weather.get_current'.
2. Summarize the weather information.
</plan>
{"tool_calls": [{"id": "call_abc", "type": "function", "function": {"name": "weather.get_current", "arguments": "{\"location\": \"London\"}"}}]}

Example Output (for a simple greeting):
<plan>
1. Provide a direct answer.
</plan>
{"tool_calls": []}
Hello! How can I assist you today?`,
		formattedTools,
	)
}

// getNexusSystemPrompt continues to use the more detailed formatToolsForLLM
func getNexusSystemPrompt(originalQuery string, plan []string, currentStepIdx int, tools []Tool) string {
	formattedTools := formatToolsForLLM(tools) // Nexus still gets full tool details

	currentPlanStep := ""
	if currentStepIdx < len(plan) {
		currentPlanStep = plan[currentStepIdx]
	}

	return fmt.Sprintf(`You are 'Nexus', the execution engine. Your task is to precisely execute the *next step* of the established plan. You must adhere to the plan and prioritize efficient action.

**Original User Request:**
%s

**The Overall Plan:**
%s

**Current Step (Step %d):**
%s

**Available Tools for Execution:**
%s

**Your Process:**
1.  **Execute the Current Step:** Based on the 'Current Step', the 'Original User Request', and the 'Conversation History', determine the exact tool call needed.
2.  **Parameter Precision:** Only include parameters that are explicitly provided in the user's *original* request or are absolutely essential for this specific step. Prefer to use tool's default values by omitting parameters if not explicitly needed.
3.  **Error Handling:** If a tool call in the 'Conversation History' resulted in an error, analyze it. If the error prevents completing the current step, either try an alternative approach (if possible within the plan) or state that the task cannot be completed and why.
4.  **Task Completion:** If this step completes the overall plan, or if no more tools are needed to fulfill the 'Original User Request', provide the final summary/answer. If the plan is complete and no more tools are needed, respond with {"tool_calls": []} and then your final answer.
5.  **No Tool Needed for Current Step:** If the current step (or the overall task) doesn't require a tool, output {"tool_calls": []} and provide a direct textual response.

**Conversation History:**
[This will be automatically appended by the LLM client, but the prompt emphasizes its importance]

**Your Next Tool Recommendation or Final Answer:**`,
		originalQuery,
		strings.Join(plan, "\n"),
		currentStepIdx+1,
		currentPlanStep,
		formattedTools,
	)
}

// formatToolsForOrchestrator provides a very concise summary for the Orchestrator LLM.
func formatToolsForOrchestrator(tools []Tool) string {
	var builder strings.Builder
	for _, tool := range tools {
		builder.WriteString(fmt.Sprintf("- %s: %s\n", tool.Function.Name, tool.Function.Description))
	}
	return builder.String()
}

// formatToolsForLLM provides detailed parameter descriptions for the Nexus LLM.
func formatToolsForLLM(tools []Tool) string {
	var builder strings.Builder
	for _, tool := range tools {
		builder.WriteString(fmt.Sprintf("- Tool Name: %s\n", tool.Function.Name))
		builder.WriteString(fmt.Sprintf("  Description: %s\n", tool.Function.Description))

		// Condense parameters for the prompt
		if tool.Function.Parameters != nil {
			var paramsMap map[string]interface{}
			// Attempt to unmarshal parameters into a map to extract properties
			paramBytes, err := json.Marshal(tool.Function.Parameters)
			if err != nil {
				builder.WriteString("  Parameters: (Error formatting parameters)\n")
				continue
			}
			if err := json.Unmarshal(paramBytes, &paramsMap); err != nil {
				builder.WriteString("  Parameters: (Error unmarshalling parameter schema)\n")
				continue
			}

			if properties, ok := paramsMap["properties"].(map[string]interface{}); ok {
				var paramDescriptions []string
				var requiredParams []string

				if req, ok := paramsMap["required"].([]interface{}); ok {
					for _, r := range req {
						if rStr, isStr := r.(string); isStr {
							requiredParams = append(requiredParams, rStr)
						}
					}
				}

				for paramName, paramSchema := range properties {
					if schemaMap, isMap := paramSchema.(map[string]interface{}); isMap {
						paramType := ""
						if t, ok := schemaMap["type"].(string); ok {
							paramType = t
						}
						// paramDesc := "" // Removed unused variable
						// if d, ok := schemaMap["description"].(string); ok {
						// 	paramDesc = d
						// }

						var enumValues []string
						if enum, ok := schemaMap["enum"].([]interface{}); ok {
							for _, e := range enum {
								if eStr, isStr := e.(string); isStr {
									enumValues = append(enumValues, eStr)
								}
							}
						}

						defaultVal := ""
						if d, ok := schemaMap["default"]; ok {
							defaultVal = fmt.Sprintf(" (default: %v)", d)
						}

						isReq := ""
						for _, rp := range requiredParams {
							if rp == paramName {
								isReq = " (required)"
								break
							}
						}

						if len(enumValues) > 0 {
							paramDescriptions = append(paramDescriptions, fmt.Sprintf("%s (%s, enum: [%s]%s)", paramName, paramType, strings.Join(enumValues, ", "), isReq))
						} else if paramType != "" {
							paramDescriptions = append(paramDescriptions, fmt.Sprintf("%s (%s%s%s)", paramName, paramType, isReq, defaultVal))
						} else {
							paramDescriptions = append(paramDescriptions, fmt.Sprintf("%s (any%s%s)", paramName, isReq, defaultVal))
						}
					}
				}
				builder.WriteString(fmt.Sprintf("  Parameters: %s\n", strings.Join(paramDescriptions, ", ")))
			} else {
				builder.WriteString("  Parameters: (complex schema, refer to tool documentation)\n")
			}
		} else {
			builder.WriteString("  Parameters: None\n")
		}
	}
	return builder.String()
}

func extractContentBetweenTags(text, startTag, endTag string) (string, bool) {
	re := regexp.MustCompile(fmt.Sprintf(`(?is)%s(.*?)%s`, regexp.QuoteMeta(startTag), regexp.QuoteMeta(endTag)))
	matches := re.FindStringSubmatch(text)
	if len(matches) > 1 {
		return strings.TrimSpace(matches[1]), true
	}
	return "", false
}

// extractToolCallsJSON attempts to find and extract the first JSON array of tool calls from a string.
// It is designed to be robust to surrounding conversational text.
func extractToolCallsJSON(text string) (string, bool) {
	// This regex looks for an opening curly brace '{' that is part of a JSON object (or array of objects)
	// and tries to match until a closing curly brace '}' or square bracket ']' that balances it.
	// This is a simplified approach and might need refinement for extremely complex or malformed JSON.
	// For tool calls, we expect an array: [{"id": "...", "function": {...}}]
	// So, we look for the outermost `[` and `]`
	re := regexp.MustCompile(`(?s)\[\s*\{.*\}\s*\]`) // Matches an array containing at least one object

	matches := re.FindString(text)
	if matches != "" {
		// Basic check for valid JSON structure
		var temp []interface{} // Use interface{} to allow any valid JSON structure
		if err := json.Unmarshal([]byte(matches), &temp); err == nil {
			return matches, true
		}
	}

	// If the above didn't work, try to find a single JSON object (e.g., if LLM omits the array brackets)
	re = regexp.MustCompile(`(?s)\{.*\}`)
	matches = re.FindString(text)
	if matches != "" {
		var temp map[string]interface{} // Use map for single object
		if err := json.Unmarshal([]byte(matches), &temp); err == nil {
			// If it's a single object, wrap it in an array to match expected ToolCalls format
			return fmt.Sprintf("[%s]", matches), true
		}
	}

	return "", false // No valid JSON found
}

func parseNumberedList(text string) []string {
	re := regexp.MustCompile(`\d+\.\s+(.*)`)
	matches := re.FindAllStringSubmatch(text, -1)
	var items []string
	for _, match := range matches {
		if len(match) > 1 {
			items = append(items, strings.TrimSpace(match[1]))
		}
	}
	return items
}
